{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f82267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Titanic dataset downloaded!\n",
      "üìä Shape: (891, 15)\n",
      "üéØ Target variable: 'survived' (0=died, 1=survived)\n",
      "\n",
      "üìã First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 1: Using seaborn (easiest - Titanic is built-in)\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# Save it locally for future use\n",
    "titanic.to_csv('../Data/titanic.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Titanic dataset downloaded!\")\n",
    "print(f\"üìä Shape: {titanic.shape}\")\n",
    "print(f\"üéØ Target variable: 'survived' (0=died, 1=survived)\")\n",
    "print(\"\\nüìã First few rows:\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c068573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Analysis:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "Missing percentages:\n",
      "survived        0.00\n",
      "pclass          0.00\n",
      "sex             0.00\n",
      "age            19.87\n",
      "sibsp           0.00\n",
      "parch           0.00\n",
      "fare            0.00\n",
      "embarked        0.22\n",
      "class           0.00\n",
      "who             0.00\n",
      "adult_male      0.00\n",
      "deck           77.22\n",
      "embark_town     0.22\n",
      "alive           0.00\n",
      "alone           0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(titanic.isnull().sum())\n",
    "print(f\"\\nMissing percentages:\")\n",
    "print((titanic.isnull().sum() / len(titanic) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6904d7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Dropping 'deck' column (77% missing)\n",
      "Columns before: 15 ‚Üí After: 14\n"
     ]
    }
   ],
   "source": [
    "# Step 1: DROP the deck column (77% missing - too unreliable)\n",
    "print(\"üóëÔ∏è Dropping 'deck' column (77% missing)\")\n",
    "titanic_clean = titanic.drop('deck', axis=1)\n",
    "print(f\"Columns before: {titanic.shape[1]} ‚Üí After: {titanic_clean.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "156c3e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üö¢ Handling missing embarkation ports:\n",
      "Embarked value counts:\n",
      "embarked\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: count, dtype: int64\n",
      "‚úÖ Filled 2 missing embarked values with 'S'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdul Salam M\\AppData\\Local\\Temp\\ipykernel_23072\\2014833449.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  titanic_clean['embarked'].fillna(mode_embarked, inplace=True)\n",
      "C:\\Users\\Abdul Salam M\\AppData\\Local\\Temp\\ipykernel_23072\\2014833449.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  titanic_clean['embark_town'].fillna('Southampton', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: FILL embarked (only 2 missing - use most common)\n",
    "print(\"\\nüö¢ Handling missing embarkation ports:\")\n",
    "print(\"Embarked value counts:\")\n",
    "print(titanic_clean['embarked'].value_counts())\n",
    "\n",
    "# Fill with most common port (Southampton = 'S')\n",
    "mode_embarked = titanic_clean['embarked'].mode()[0]\n",
    "titanic_clean['embarked'].fillna(mode_embarked, inplace=True)\n",
    "titanic_clean['embark_town'].fillna('Southampton', inplace=True)\n",
    "\n",
    "print(f\"‚úÖ Filled 2 missing embarked values with '{mode_embarked}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45817dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë∂ Handling missing ages:\n",
      "Age by passenger class and sex:\n",
      "pclass  sex   \n",
      "1       female    35.0\n",
      "        male      40.0\n",
      "2       female    28.0\n",
      "        male      30.0\n",
      "3       female    21.5\n",
      "        male      25.0\n",
      "Name: age, dtype: float64\n",
      "‚úÖ Filled 177 missing ages using class-sex median\n"
     ]
    }
   ],
   "source": [
    "# Step 3: IMPUTE age (19% missing - use smart strategy)\n",
    "print(\"\\nüë∂ Handling missing ages:\")\n",
    "print(\"Age by passenger class and sex:\")\n",
    "age_by_groups = titanic_clean.groupby(['pclass', 'sex'])['age'].median()\n",
    "print(age_by_groups)\n",
    "\n",
    "# Fill missing ages based on passenger class and sex\n",
    "def fill_age(row):\n",
    "    if pd.isna(row['age']):\n",
    "        return age_by_groups[row['pclass'], row['sex']]\n",
    "    return row['age']\n",
    "\n",
    "titanic_clean['age'] = titanic_clean.apply(fill_age, axis=1)\n",
    "print(f\"‚úÖ Filled {177} missing ages using class-sex median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2134747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç VERIFICATION - Missing values after cleaning:\n",
      "Series([], dtype: int64)\n",
      "üéâ SUCCESS! No missing values remaining!\n",
      "\n",
      "üìä Final dataset shape: (891, 14)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: VERIFY our cleaning worked\n",
    "print(\"\\nüîç VERIFICATION - Missing values after cleaning:\")\n",
    "missing_after = titanic_clean.isnull().sum()\n",
    "print(missing_after[missing_after > 0])  # Only show columns with missing values\n",
    "\n",
    "if missing_after.sum() == 0:\n",
    "    print(\"üéâ SUCCESS! No missing values remaining!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Still have missing values to handle\")\n",
    "    \n",
    "print(f\"\\nüìä Final dataset shape: {titanic_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8264c5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Cleaned dataset preview:\n",
      "Age column now complete:\n",
      "Age range: 0.4 - 80.0\n",
      "Average age: 29.1\n",
      "\n",
      "First 5 rows of cleaned data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male  embark_town alive  alone  \n",
       "0    man        True  Southampton    no  False  \n",
       "1  woman       False    Cherbourg   yes  False  \n",
       "2  woman       False  Southampton   yes   True  \n",
       "3  woman       False  Southampton   yes  False  \n",
       "4    man        True  Southampton    no   True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: QUICK PREVIEW of our cleaned data\n",
    "print(\"\\nüìã Cleaned dataset preview:\")\n",
    "print(\"Age column now complete:\")\n",
    "print(f\"Age range: {titanic_clean['age'].min():.1f} - {titanic_clean['age'].max():.1f}\")\n",
    "print(f\"Average age: {titanic_clean['age'].mean():.1f}\")\n",
    "\n",
    "print(\"\\nFirst 5 rows of cleaned data:\")\n",
    "titanic_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce416494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî§ Converting categorical variables to numerical...\n",
      "‚úÖ Categorical encoding complete!\n",
      "New columns created: ['sex_male', 'port_C', 'port_Q', 'port_S']\n"
     ]
    }
   ],
   "source": [
    "# Step 6: CATEGORICAL ENCODING - Convert text to numbers\n",
    "print(\"üî§ Converting categorical variables to numerical...\")\n",
    "\n",
    "# Create a copy to work with\n",
    "titanic_ml = titanic_clean.copy()\n",
    "\n",
    "# Binary encoding for sex (0=female, 1=male)\n",
    "titanic_ml['sex_male'] = (titanic_ml['sex'] == 'male').astype(int)\n",
    "\n",
    "# One-hot encoding for embarked ports\n",
    "titanic_ml = pd.get_dummies(titanic_ml, columns=['embarked'], prefix='port')\n",
    "\n",
    "print(\"‚úÖ Categorical encoding complete!\")\n",
    "print(f\"New columns created: {[col for col in titanic_ml.columns if col.startswith('port_') or col == 'sex_male']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7ac852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Creating new features...\n",
      "‚úÖ New features created:\n",
      "‚Ä¢ Family size: 1-11\n",
      "‚Ä¢ Age groups: ['age_Child', 'age_Teen', 'age_Young_Adult', 'age_Adult', 'age_Senior']\n",
      "‚Ä¢ Fare categories: ['fare_Low', 'fare_Medium', 'fare_High', 'fare_Very_High']\n"
     ]
    }
   ],
   "source": [
    "# Step 7: FEATURE ENGINEERING - Create meaningful new features\n",
    "print(\"\\nüîß Creating new features...\")\n",
    "\n",
    "# Family size and relationships\n",
    "titanic_ml['family_size'] = titanic_ml['sibsp'] + titanic_ml['parch'] + 1\n",
    "titanic_ml['is_alone'] = (titanic_ml['family_size'] == 1).astype(int)\n",
    "\n",
    "# Age groups (more interpretable than raw age)\n",
    "titanic_ml['age_group'] = pd.cut(titanic_ml['age'], \n",
    "                                bins=[0, 12, 18, 35, 60, 100], \n",
    "                                labels=['Child', 'Teen', 'Young_Adult', 'Adult', 'Senior'])\n",
    "\n",
    "# Convert age groups to dummy variables\n",
    "titanic_ml = pd.get_dummies(titanic_ml, columns=['age_group'], prefix='age')\n",
    "\n",
    "# Fare categories (economic status indicator)\n",
    "titanic_ml['fare_category'] = pd.cut(titanic_ml['fare'], \n",
    "                                    bins=[0, 7.91, 14.45, 31.0, 512.33], \n",
    "                                    labels=['Low', 'Medium', 'High', 'Very_High'])\n",
    "\n",
    "titanic_ml = pd.get_dummies(titanic_ml, columns=['fare_category'], prefix='fare')\n",
    "\n",
    "print(\"‚úÖ New features created:\")\n",
    "print(f\"‚Ä¢ Family size: {titanic_ml['family_size'].min()}-{titanic_ml['family_size'].max()}\")\n",
    "print(f\"‚Ä¢ Age groups: {[col for col in titanic_ml.columns if col.startswith('age_')]}\")\n",
    "print(f\"‚Ä¢ Fare categories: {[col for col in titanic_ml.columns if col.startswith('fare_')]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5e51ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Selecting features for logistic regression...\n",
      "‚úÖ Final feature set:\n",
      "‚Ä¢ Features (X): (891, 18)\n",
      "‚Ä¢ Target (y): (891,)\n",
      "‚Ä¢ Feature names: ['pclass', 'sex_male', 'age', 'family_size', 'is_alone', 'fare', 'port_C', 'port_Q', 'port_S', 'age_Child', 'age_Teen', 'age_Young_Adult', 'age_Adult', 'age_Senior', 'fare_Low', 'fare_Medium', 'fare_High', 'fare_Very_High']\n"
     ]
    }
   ],
   "source": [
    "# Step 8: SELECT FINAL FEATURES for modeling\n",
    "print(\"\\nüéØ Selecting features for logistic regression...\")\n",
    "\n",
    "# Features to use in our model\n",
    "features_to_use = [\n",
    "    # Demographics\n",
    "    'pclass', 'sex_male', 'age',\n",
    "    # Family\n",
    "    'family_size', 'is_alone',\n",
    "    # Economic\n",
    "    'fare',\n",
    "    # Embarkation ports\n",
    "    'port_C', 'port_Q', 'port_S',\n",
    "    # Age groups\n",
    "    'age_Child', 'age_Teen', 'age_Young_Adult', 'age_Adult', 'age_Senior',\n",
    "    # Fare categories  \n",
    "    'fare_Low', 'fare_Medium', 'fare_High', 'fare_Very_High'\n",
    "]\n",
    "\n",
    "# Create final dataset\n",
    "X = titanic_ml[features_to_use]\n",
    "y = titanic_ml['survived']\n",
    "\n",
    "print(f\"‚úÖ Final feature set:\")\n",
    "print(f\"‚Ä¢ Features (X): {X.shape}\")\n",
    "print(f\"‚Ä¢ Target (y): {y.shape}\")\n",
    "print(f\"‚Ä¢ Feature names: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2610ae40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Splitting data into train and test sets...\n",
      "‚úÖ Data split complete:\n",
      "‚Ä¢ Training set: 712 passengers\n",
      "‚Ä¢ Test set: 179 passengers\n",
      "‚Ä¢ Training survival rate: 38.3%\n",
      "‚Ä¢ Test survival rate: 38.5%\n"
     ]
    }
   ],
   "source": [
    "# Step 9: SPLIT DATA for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"üìä Splitting data into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data split complete:\")\n",
    "print(f\"‚Ä¢ Training set: {X_train.shape[0]} passengers\")\n",
    "print(f\"‚Ä¢ Test set: {X_test.shape[0]} passengers\")\n",
    "print(f\"‚Ä¢ Training survival rate: {y_train.mean():.1%}\")\n",
    "print(f\"‚Ä¢ Test survival rate: {y_test.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa1f943d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Creating logistic regression model...\n",
      "üèãÔ∏è Training the model...\n",
      "‚úÖ Model training complete!\n",
      "‚Ä¢ Model type: LogisticRegression\n",
      "‚Ä¢ Features used: 18\n",
      "‚Ä¢ Training samples: 712\n"
     ]
    }
   ],
   "source": [
    "# Step 10: CREATE and TRAIN the logistic regression model\n",
    "print(\"\\nü§ñ Creating logistic regression model...\")\n",
    "\n",
    "# Create the model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "print(\"üèãÔ∏è Training the model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Model training complete!\")\n",
    "print(f\"‚Ä¢ Model type: {type(model).__name__}\")\n",
    "print(f\"‚Ä¢ Features used: {len(X_train.columns)}\")\n",
    "print(f\"‚Ä¢ Training samples: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7826ad49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÆ Making predictions...\n",
      "‚úÖ Predictions complete!\n",
      "üéØ Model Accuracy: 81.0%\n",
      "üìä Detailed Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.83      0.87      0.85       110\n",
      "    Survived       0.78      0.71      0.74        69\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.80      0.79      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 11: MAKE PREDICTIONS and EVALUATE performance\n",
    "print(\"\\nüîÆ Making predictions...\")\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probability of survival\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"‚úÖ Predictions complete!\")\n",
    "print(f\"üéØ Model Accuracy: {accuracy:.1%}\")\n",
    "print(f\"üìä Detailed Results:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Died', 'Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3938a8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Creating advanced features...\n",
      "‚úÖ Advanced features created!\n"
     ]
    }
   ],
   "source": [
    "# Step 12: CREATE ADVANCED FEATURES\n",
    "print(\"üîß Creating advanced features...\")\n",
    "\n",
    "# Title extraction from names (social status indicator)\n",
    "titanic_ml['title'] = titanic_clean['who'].copy()  # Use existing 'who' column\n",
    "titanic_ml = pd.get_dummies(titanic_ml, columns=['title'], prefix='title')\n",
    "\n",
    "# Fare per person (family economics)\n",
    "titanic_ml['fare_per_person'] = titanic_ml['fare'] / titanic_ml['family_size']\n",
    "\n",
    "# Age-Class interaction (young first class vs old third class)\n",
    "titanic_ml['age_pclass_interaction'] = titanic_ml['age'] * titanic_ml['pclass']\n",
    "\n",
    "# Family survival strategy\n",
    "titanic_ml['family_survival_strategy'] = (\n",
    "    (titanic_ml['family_size'] > 1) & (titanic_ml['age'] < 18)\n",
    ").astype(int)\n",
    "\n",
    "print(\"‚úÖ Advanced features created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49244f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Finding optimal hyperparameters...\n",
      "‚úÖ Best parameters: {'C': 1.0, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "‚úÖ Best CV score: 0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "80 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1363, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1210, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1363, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1220, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [0.7837585  0.70371319 0.77249089 0.70791884        nan        nan\n",
      " 0.7837585  0.7205949  0.77249089 0.73183296        nan        nan\n",
      " 0.7950261  0.70791884 0.7964444  0.71073574        nan        nan\n",
      " 0.7950261  0.73324141 0.7964444  0.73603861        nan        nan\n",
      " 0.7936472  0.70932729 0.7922486  0.71073574        nan        nan\n",
      " 0.7936472  0.73603861 0.7922486  0.73603861        nan        nan\n",
      " 0.79503595 0.71073574 0.79503595 0.71073574        nan        nan\n",
      " 0.79503595 0.73603861 0.79503595 0.73603861        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 13: HYPERPARAMETER OPTIMIZATION\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"üîç Finding optimal hyperparameters...\")\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0, 10.0, 100.0],  # Regularization strength\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],  # Regularization type\n",
    "    'solver': ['liblinear', 'saga'],  # Optimization algorithm\n",
    "    'max_iter': [1000, 2000]\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"‚úÖ Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"‚úÖ Best CV score: {grid_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bdaba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Selecting most important features...\n",
      "Selected features: ['pclass', 'sex_male', 'age', 'is_alone', 'fare', 'port_C', 'port_S', 'age_Child', 'fare_Low', 'fare_Very_High']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE selected features: ['pclass', 'sex_male', 'family_size', 'is_alone', 'port_Q', 'age_Child', 'age_Adult', 'age_Senior', 'fare_Low', 'fare_Medium', 'fare_High', 'fare_Very_High']\n"
     ]
    }
   ],
   "source": [
    "# Step 14: FEATURE SELECTION\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "\n",
    "print(\"üéØ Selecting most important features...\")\n",
    "\n",
    "# Method A: Statistical feature selection\n",
    "selector = SelectKBest(score_func=chi2, k=10)  # Top 10 features\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "selected_features = X_train.columns[selector.get_support()]\n",
    "print(f\"Selected features: {list(selected_features)}\")\n",
    "\n",
    "# Method B: Recursive Feature Elimination\n",
    "rfe = RFE(LogisticRegression(random_state=42), n_features_to_select=12)\n",
    "rfe.fit(X_train, y_train)\n",
    "rfe_features = X_train.columns[rfe.support_]\n",
    "print(f\"RFE selected features: {list(rfe_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14def765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Cross-validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic          : 0.803 (+/- 0.048)\n",
      "Tuned          : 0.798 (+/- 0.044)\n",
      "L1_Regularized : 0.782 (+/- 0.044)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2_Regularized : 0.796 (+/- 0.037)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Step 15: ROBUST EVALUATION\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "print(\"üìä Cross-validation evaluation...\")\n",
    "\n",
    "# Stratified K-Fold (maintains class balance)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Test multiple models\n",
    "models = {\n",
    "    'Basic': LogisticRegression(random_state=42),\n",
    "    'Tuned': best_model,\n",
    "    'L1_Regularized': LogisticRegression(penalty='l1', solver='liblinear', C=0.1, random_state=42),\n",
    "    'L2_Regularized': LogisticRegression(penalty='l2', C=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    print(f\"{name:15}: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f1d4866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è Handling class imbalance...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚öñÔ∏è Handling class imbalance...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Calculate class weights\u001b[39;00m\n\u001b[32m      7\u001b[39m class_weights = compute_class_weight(\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     classes=\u001b[43mnp\u001b[49m.unique(y_train), \n\u001b[32m     10\u001b[39m     y=y_train\n\u001b[32m     11\u001b[39m )\n\u001b[32m     12\u001b[39m class_weight_dict = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(np.unique(y_train), class_weights))\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Model with balanced class weights\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 16: ADDRESS CLASS IMBALANCE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "print(\"‚öñÔ∏è Handling class imbalance...\")\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced', \n",
    "    classes=np.unique(y_train), \n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# Model with balanced class weights\n",
    "balanced_model = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "balanced_model.fit(X_train, y_train)\n",
    "balanced_pred = balanced_model.predict(X_test)\n",
    "balanced_accuracy = accuracy_score(y_test, balanced_pred)\n",
    "\n",
    "print(f\"Balanced model accuracy: {balanced_accuracy:.3f}\")\n",
    "print(f\"Class weights: {class_weight_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78694ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creating polynomial features...\n",
      "Polynomial features accuracy: 0.793\n",
      "Feature count: 18 ‚Üí 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdul Salam M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Step 17: POLYNOMIAL FEATURES (interaction terms)\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "print(\"üîÑ Creating polynomial features...\")\n",
    "\n",
    "# Create interaction terms (degree=2)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Train with polynomial features\n",
    "poly_model = LogisticRegression(C=0.1, max_iter=2000, random_state=42)\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "poly_pred = poly_model.predict(X_test_poly)\n",
    "poly_accuracy = accuracy_score(y_test, poly_pred)\n",
    "\n",
    "print(f\"Polynomial features accuracy: {poly_accuracy:.3f}\")\n",
    "print(f\"Feature count: {X_train.shape[1]} ‚Üí {X_train_poly.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a53c10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Clean model comparison...\n",
      "Model Performance Comparison:\n",
      "--------------------------------------------------\n",
      "Baseline            : Train=0.819, Test=0.810\n",
      "Regularized_L1      : Train=0.812, Test=0.810\n",
      "Regularized_L2      : Train=0.819, Test=0.810\n",
      "Balanced_Classes    : Train=0.802, Test=0.799\n"
     ]
    }
   ],
   "source": [
    "# First, fix the import issue\n",
    "import numpy as np\n",
    "\n",
    "# Step 18: CLEAN MODEL COMPARISON (no errors!)\n",
    "print(\"üßπ Clean model comparison...\")\n",
    "\n",
    "# Simple, working models\n",
    "models_clean = {\n",
    "    'Baseline': LogisticRegression(random_state=42, max_iter=2000),\n",
    "    'Regularized_L1': LogisticRegression(penalty='l1', solver='liblinear', C=1.0, random_state=42),\n",
    "    'Regularized_L2': LogisticRegression(penalty='l2', C=1.0, max_iter=2000, random_state=42),\n",
    "    'Balanced_Classes': LogisticRegression(class_weight='balanced', max_iter=2000, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name, model in models_clean.items():\n",
    "    # Train and test\n",
    "    model.fit(X_train, y_train)\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    \n",
    "    print(f\"{name:<20}: Train={train_score:.3f}, Test={test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7949a0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç What features matter most?\n",
      "Top 10 Most Important Features:\n",
      "           feature  coefficient  abs_coefficient\n",
      "1         sex_male    -2.547501         2.547501\n",
      "0           pclass    -1.039991         1.039991\n",
      "9        age_Child     0.971110         0.971110\n",
      "17  fare_Very_High     0.645187         0.645187\n",
      "15     fare_Medium     0.600081         0.600081\n",
      "16       fare_High     0.558584         0.558584\n",
      "4         is_alone    -0.501588         0.501588\n",
      "10        age_Teen    -0.407292         0.407292\n",
      "3      family_size    -0.400520         0.400520\n",
      "14        fare_Low     0.353460         0.353460\n"
     ]
    }
   ],
   "source": [
    "# Step 19: FEATURE IMPORTANCE ANALYSIS\n",
    "print(\"\\nüîç What features matter most?\")\n",
    "\n",
    "# Use the best performing model\n",
    "best_simple_model = LogisticRegression(max_iter=2000, random_state=42)\n",
    "best_simple_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'coefficient': best_simple_model.coef_[0],\n",
    "    'abs_coefficient': np.abs(best_simple_model.coef_[0])\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc0a1645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Final Results Summary:\n",
      "‚úÖ Final Model Accuracy: 81.0%\n",
      "üìä Improvement from start: 81.0% vs 81.0%\n",
      "\n",
      "Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.83      0.87      0.85       110\n",
      "    Survived       0.78      0.71      0.74        69\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.80      0.79      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 20: FINAL MODEL EVALUATION\n",
    "print(\"\\nüèÜ Final Results Summary:\")\n",
    "\n",
    "final_model = LogisticRegression(max_iter=2000, random_state=42)\n",
    "final_model.fit(X_train, y_train)\n",
    "final_predictions = final_model.predict(X_test)\n",
    "final_accuracy = accuracy_score(y_test, final_predictions)\n",
    "\n",
    "print(f\"‚úÖ Final Model Accuracy: {final_accuracy:.1%}\")\n",
    "print(f\"üìä Improvement from start: {final_accuracy:.1%} vs 81.0%\")\n",
    "\n",
    "# Classification report (clean)\n",
    "print(\"\\nDetailed Performance:\")\n",
    "print(classification_report(y_test, final_predictions, target_names=['Died', 'Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7666d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
